# NLP Tutorials using Large Language Models (LLMs)

[![made-with-python](https://img.shields.io/badge/Made%20with-Python-1f425f.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)

Welcome to the **NLP Tutorials** repository! This repository currently hosts a single project focused on **MultiHop Question Answering (QA)** using **Large Language Models (LLMs)**, which is part of a broader series of tutorials on **Natural Language Processing (NLP)**.

## ðŸ“º Watch on YouTube
Check out the video walkthroughs of this project and more on my [YouTube channel](https://www.youtube.com/@AryanKargwal)!

## ðŸš€ Projects in this Repository

| Tutorial Name                    | Description                                                                                                    | Link to Tutorial                 |
|----------------------------------|----------------------------------------------------------------------------------------------------------------|----------------------------------|
| **MultiHopQA with DSPy**          | Implements multi-hop question answering using **DSPy**, **ColBERT**, **Qwen 2.5 72B**, and **HotPotQA**.        | [multihopqa-dspy](./multihopqa-dspy) |
| **VLM Stress Testing**            | Compares the performance of multiple **Vision-Language Models** for multi-modal inferences using **Streamlit**. | [vlm-comparison](./vlm-comparison)   |


---

## MultiHopQA with DSPy, ColBERT, and Qwen 2.5 72B

This project demonstrates how to perform **MultiHop Question Answering (QA)**, a task that requires synthesizing information from multiple sources to answer complex questions. The solution integrates several state-of-the-art tools like **DSPy**, **ColBERT**, **HotPotQA**, **TuneAPI**, and **Qwen 2.5 72B**.



### Future Plans
- Additional tutorials on text generation, retrieval-augmented generation, and more will be added as part of this repository.

## VLM Stress Testing with Llama 3.2, Qwen 2 VL, and GPT 4o
This project provides a framework for evaluating Vision-Language Models (VLMs) by comparing their performance on multi-modal question-answering tasks. It allows users to upload images, input questions, and test responses across multiple state-of-the-art models like Llama 3.2, Qwen 2 VL, and GPT 4o. The application tracks key metrics like response quality, latency, and token usage to determine the best-performing model for each task.

### Future Plans
Upcoming enhancements include expanded model comparisons, fine-tuning tutorials, and automated dataset generation for advanced multi-modal tasks.

## ðŸ“œ License
This repository is licensed under the [Apache 2.0 License](https://opensource.org/licenses/Apache-2.0).

## ðŸ“º Watch More
Don't forget to subscribe and check out more tutorials on my [YouTube channel](https://www.youtube.com/@AryanKargwal).
